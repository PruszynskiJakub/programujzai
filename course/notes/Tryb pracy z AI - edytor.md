# Tryb pracy z AI - edytor

## Wprowadzenie

Wsp贸prac z agentem AI do generacji kodu rozpoczynamy od trybu edytora. Przez tryb edytora rozumiemy orkiestrowanie modelu, aby wprowadza zmiany bezporednio do pliku.

## Zasilanie kontekstu - klucz do sukcesu

Cay proces rozpoczyna si od prostego, jednak bardzo istotnego kroku: **zasilenia kontekstu**. Nale偶y znale藕 zdrowy balans, co przychodzi g贸wnie z praktyk. [[Poziomy szczeg贸owoci promptu]] mo偶e by pomocnym 藕r贸dem.

Przy pojawieniu si atwo dostpnych LLM-贸w pojawia si r贸wnie偶 ogromna pokusa zasilenia modelu penym kodem 藕r贸dowym projektu. Wraz z upywem czasu ta pr贸ba si nie obronia. Czy jest to mo偶liwe?

Tak! Istniej modele posiadajce bardzo szerokie okno kontekstowe, jak na przykad Googlowe Gemini. Jednak dlaczego tak wietnie zapowiadajcy si eksperyment nie wypali? Pot偶na ilo kontekstu najzwyczajniej tworzy szum. LLM nie jest skupiony na zadaniu, ale na bardzo og贸lnikowych danych, co skutkuje r贸wnie og贸lnikowymi wynikami.

### Jak robi to efektywnie? 

Dodajemy do kontekstu minimaln ilo plik贸w wymaganych do wykonania zadania. Wyobra藕 sobie, 偶e sterujesz juniorem - chcesz mu przekaza kontekst, nie za du偶o bo si pogubi, ale te偶 nie za may bo bdzie mu brakowao potrzebnych informacji i gdzie popeni bd.

>  Je偶eli agent, kt贸rego u偶ywasz, ma mo偶liwo dodawania plik贸w read-only, korzystaj z tego. Ograniczy to skupienie edycji tylko na konkretnych plikach.

## Budowanie efektywnego promptu

Kolejny krok to zbudowanie konkretnego promptu, kt贸rego egzekucja pozwoli nam uzyska po偶dany rezultat.

Prompt powinien by r贸wnie偶 ograniczony do minimum. Staraj si u偶ywa [[Sowa bogate znaczeniowo]]. Je偶eli posiadasz plik, kt贸ry chcesz edytowa, wska偶 go, to samo z konkretn metod. W skr贸cie: zamiast rcznie wprowadza kod, skupiamy si na tym, co chcemy osign, bez potrzeby podawania konkretnych detali technologicznych.

## Mentalno problem first

Mo偶na si zastanowi - gdzie haczyk? Czy to jest zoty rodek? Czy ju偶 nie musz zna jzyka, a ka偶dy z ulicy zastpi mnie na moim stanowisku?

Ot贸偶 nie. Narzdzia pokroju Aider potrafi bardzo przypieszy nasz produktywno, pozwalaj skupi si na problemie, niekoniecznie na detalach.

[[Mentalno problem first]] jest kluczowa. To na problemie si skupiamy. Najwikszy boost produktywnoci zyskamy dopiero, kiedy wietnie go rozumiemy i potrafimy go rozwiza bez wsparcia LLM. 

Kiedy sami nie jestemy w stanie upora si z problemem albo nie mamy jeszcze pomysu, pojawi si spora ilo irytacji. Naprowadzanie LLM na rozwizanie, kt贸rego nie jestemy pewni, miewa poczucie stania w miejscu. Klasyczne modelowanie iteracyjne daje nam poczucie powolnego poruszania si do przodu, zakoczone pot偶nym refaktorem po uzyskaniu oczekiwanego rezultatu.

## Jako kodu i rola recenzenta

Na koniec wr贸my do tych detali, na kt贸rych jak wspomnielimy, nie skupiamy si. Czy musi to oznacza obni偶enie jakoci naszego kodu? 

Ot贸偶 nie. Nasze umiejtnoci recenzowania kodu, kt贸re pozyskalimy, powinny by teraz bardzo istotne. LLM ma nam pom贸c szybko dostarczy upragnione rozwizanie, skupi si na biznesie, a kiedy ju偶 je mamy - skupmy si na weryfikacji, powimy niezbdny czas na refaktor.

##  Kluczowe wnioski

- **Minimalizm kontekstowy** - dodawaj do kontekstu tylko niezbdne pliki
- **Precyzyjne prompty** - u偶ywaj bogatych znaczeniowo s贸w, wskazuj konkretne pliki i metody
- **Problem first** - najpierw zrozum problem, potem wykorzystaj AI do implementacji
- **Mentalno recenzenta** - zawsze weryfikuj i refaktoruj kod wygenerowany przez AI
- **Balans** - znajd藕 r贸wnowag midzy szybkoci dostarczania a jakoci kodu

## Zadanie

1. Wybierz prosty problem programistyczny, kt贸ry znasz i rozumiesz.
2. Przygotuj minimalny zestaw plik贸w kontekstowych.
3. Sformuuj precyzyjny prompt dla AI, skupiajc si na problemie, nie na implementacji.
4. Po wygenerowaniu rozwizania, przeprowad藕 dokadny code review.
5. Zastan贸w si: co mo偶esz poprawi w swoim podejciu do wsp贸pracy z AI?

Jak zmienia si Twoje podejcie do programowania, gdy pracujesz z AI jako asystentem? Czy zauwa偶asz, 偶e wicej czasu powicasz na zrozumienie problemu, a mniej na pisanie kodu?