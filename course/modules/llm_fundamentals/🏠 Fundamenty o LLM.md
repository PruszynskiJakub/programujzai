## Wprowadzenie

Modele jÄ™zykowe (LLM) zrewolucjonizowaÅ‚y sposÃ³b, w jaki wchodzimy w interakcjÄ™ z technologiÄ…. Zanim zaczniemy wykorzystywaÄ‡ je w praktyce, warto zrozumieÄ‡ podstawowe mechanizmy ich dziaÅ‚ania. Ta lekcja wprowadza kluczowe koncepcje, ktÃ³re pozwolÄ… ci lepiej zrozumieÄ‡ moÅ¼liwoÅ›ci i ograniczenia tych narzÄ™dzi.

## Jak dziaÅ‚ajÄ… modele jÄ™zykowe?

Modele jÄ™zykowe to zaawansowane systemy sztucznej inteligencji, ktÃ³re przetwarzajÄ… i generujÄ… tekst w sposÃ³b przypominajÄ…cy ludzkie rozumowanie. Ich dziaÅ‚anie opiera siÄ™ na kilku fundamentalnych koncepcjach:

https://www.youtube.com/watch?v=LPZh9BOjkQs

### Tokenizacja

Tokenizacja to proces zamiany tekstu na reprezentacjÄ™ liczbowÄ…, ktÃ³rÄ… model moÅ¼e przetwarzaÄ‡.

- WspÃ³Å‚czesne modele wykorzystujÄ… gÅ‚Ã³wnie subword tokenization â€“ dzielenie tekstu na fragmenty sÅ‚Ã³w.
- KaÅ¼dy token (fragment sÅ‚owa) jest reprezentowany przez liczbÄ™ w sÅ‚owniku modelu.
- Model generuje odpowiedzi token po tokenie, odpowiadajÄ…c na pytanie: "Jaki token stanowi najlepszÄ… kontynuacjÄ™ dotychczasowego tekstu?"

PrzykÅ‚ady narzÄ™dzi do tokenizacji:

- [platform.openai.com/tokenizer](https://platform.openai.com/tokenizer)
- [tiktokenizer.vercel.app](https://tiktokenizer.vercel.app)

Warto pamiÄ™taÄ‡, Å¼e wiÄ™kszoÅ›Ä‡ modeli jest zoptymalizowana pod kÄ…tem jÄ™zyka angielskiego. Teksty w innych jÄ™zykach mogÄ… wymagaÄ‡ wiÄ™kszej liczby tokenÃ³w, co zwiÄ™ksza koszty interakcji z modelem.

### Embeddingi

Embedding to reprezentacja znaczenia sÅ‚Ã³w i zdaÅ„ za pomocÄ… wektorÃ³w liczbowych. DziÄ™ki embeddingom modele mogÄ… "rozumieÄ‡" semantyczne relacje miÄ™dzy sÅ‚owami i zdaniami.

WyrÃ³Å¼niamy dwa gÅ‚Ã³wne rodzaje embeddingÃ³w:

- **Word embedding** â€“ reprezentacja znaczenia pojedynczych sÅ‚Ã³w.
  - SÅ‚owa o podobnym znaczeniu majÄ… podobne wartoÅ›ci wektorÃ³w.
- **Sentence embedding** â€“ reprezentacja znaczenia caÅ‚ych zdaÅ„ lub fragmentÃ³w tekstu.
  - UwzglÄ™dnia kontekst uÅ¼ycia sÅ‚Ã³w.
  - Wykorzystywany w bazach wektorowych do wyszukiwania podobnych treÅ›ci.

PrzykÅ‚adowe modele embeddingÃ³w od OpenAI:

- `text-embedding-ada-002` (1536 wymiarÃ³w)
- `text-embedding-3-small` (1536 wymiarÃ³w)
- `text-embedding-3-large` (3072 wymiary)

### Kontekst

Kontekst to kluczowy element dziaÅ‚ania modeli jÄ™zykowych, determinujÄ…cy ich zdolnoÅ›Ä‡ do generowania spÃ³jnych odpowiedzi. Åšwiadome zarzÄ…dzanie kontekstem jest fundamentem efektywnej pracy z LLM.

#### Tokeny wejÅ›ciowe vs wyjÅ›ciowe

KaÅ¼dy model ma dwa kluczowe ograniczenia kontekstowe:

- **Tokeny wejÅ›ciowe (input tokens)** â€“ maksymalna liczba tokenÃ³w, ktÃ³re moÅ¼emy przekazaÄ‡ do modelu.
  - ObejmujÄ… prompt, historiÄ™ konwersacji i dodatkowe dane.
  - Limity wynoszÄ… zwykle od 4k do 32k tokenÃ³w.
- **Tokeny wyjÅ›ciowe (output tokens)** â€“ maksymalna liczba tokenÃ³w, ktÃ³re model moÅ¼e wygenerowaÄ‡ w odpowiedzi.
  - Limity wynoszÄ… zwykle od 4k do 8k tokenÃ³w.
  - Przy dÅ‚ugich odpowiedziach model moÅ¼e "zapomnieÄ‡" wczeÅ›niejsze instrukcje.

#### Strategie zarzÄ…dzania kontekstem

Efektywne zarzÄ…dzanie kontekstem wymaga:

- Ekonomicznego formuÅ‚owania promptÃ³w â€“ unikanie zbÄ™dnych powtÃ³rzeÅ„.
- Priorytetyzacji informacji â€“ najwaÅ¼niejsze dane umieszczaj na poczÄ…tku i koÅ„cu promptu.
- Chunkingu â€“ dzielenie duÅ¼ych dokumentÃ³w na mniejsze fragmenty.
- Kompresji kontekstu â€“ streszczanie wczeÅ›niejszych czÄ™Å›ci konwersacji.
- Åšwiadomego zarzÄ…dzania historiÄ… â€“ usuwanie nieistotnych fragmentÃ³w wczeÅ›niejszej konwersacji.

#### Implikacje praktyczne

Ograniczenia kontekstu majÄ… bezpoÅ›redni wpÅ‚yw na:

- **Koszt** â€“ wiÄ™kszy kontekst oznacza wiÄ™cej tokenÃ³w i wyÅ¼szy koszt uÅ¼ycia API.
- **WydajnoÅ›Ä‡** â€“ dÅ‚uÅ¼szy kontekst wydÅ‚uÅ¼a czas przetwarzania.
- **JakoÅ›Ä‡ odpowiedzi** â€“ zbyt duÅ¼y kontekst moÅ¼e prowadziÄ‡ do "rozmycia uwagi" modelu.
- **PamiÄ™Ä‡ konwersacji** â€“ zdolnoÅ›Ä‡ modelu do odnoszenia siÄ™ do wczeÅ›niejszych czÄ™Å›ci dialogu.

## GÅ‚Ã³wni dostawcy modeli LLM

Na rynku dostÄ™pnych jest kilku znaczÄ…cych dostawcÃ³w modeli jÄ™zykowych:

- **OpenAI** â€“ twÃ³rca modeli GPT (GPT-3.5, GPT-4)
- **Anthropic** â€“ twÃ³rca modeli Claude
- **Google** â€“ twÃ³rca modeli Gemini (dawniej Bard)
- **DeepSeek** â€“ specjalizujÄ…cy siÄ™ w modelach do zastosowaÅ„ naukowych
- **Ollama** â€“ oferujÄ…cy rozwiÄ…zania do lokalnego uruchamiania modeli

KaÅ¼dy z dostawcÃ³w oferuje modele o rÃ³Å¼nych moÅ¼liwoÅ›ciach, ograniczeniach i specjalizacjach.

## Zadania praktyczne

### Zadanie 1: Eksperyment z tokenizacjÄ…

Przetestuj tokenizacjÄ™ rÃ³Å¼nych tekstÃ³w za pomocÄ… narzÄ™dzia [tiktokenizer.vercel.app](https://tiktokenizer.vercel.app):

- PorÃ³wnaj liczbÄ™ tokenÃ³w potrzebnych do wyraÅ¼enia tego samego zdania w jÄ™zyku angielskim i polskim.
- SprawdÅº, jak tokenizowane sÄ… terminy techniczne, nazwy wÅ‚asne i emoji.
- Jakie implikacje ma to dla projektowania promptÃ³w i zarzÄ…dzania kontekstem?

### Zadanie 2: ZarzÄ…dzanie kontekstem

Zaprojektuj strategiÄ™ zarzÄ…dzania kontekstem dla nastÄ™pujÄ…cych scenariuszy:

- Analiza dÅ‚ugiego dokumentu (20+ stron) z wykorzystaniem LLM.
- Prowadzenie wieloetapowej konwersacji z modelem, ktÃ³ra wymaga "pamiÄ™tania" wczeÅ›niejszych ustaleÅ„.
- Generowanie dÅ‚ugiej, spÃ³jnej odpowiedzi przekraczajÄ…cej standardowy limit tokenÃ³w wyjÅ›ciowych.

## Podsumowanie

Zrozumienie fundamentÃ³w dziaÅ‚ania modeli jÄ™zykowych â€“ tokenizacji, embeddingÃ³w i kontekstu â€“ pozwala na bardziej Å›wiadome i efektywne wykorzystanie tych narzÄ™dzi. SzczegÃ³lnie istotne jest opanowanie sztuki zarzÄ…dzania kontekstem, ktÃ³ra bezpoÅ›rednio wpÅ‚ywa na jakoÅ›Ä‡ interakcji z LLM, koszty operacyjne i moÅ¼liwoÅ›ci zastosowaÅ„.

W kolejnych lekcjach bÄ™dziemy zgÅ‚Ä™biaÄ‡ praktyczne aspekty pracy z LLM, opierajÄ…c siÄ™ na tych podstawowych koncepcjach.

ğŸš§ **Uwaga:** Technologia LLM rozwija siÄ™ bardzo dynamicznie. Informacje przedstawione w tej lekcji mogÄ… ulec zmianie wraz z pojawieniem siÄ™ nowych modeli i rozwiÄ…zaÅ„.