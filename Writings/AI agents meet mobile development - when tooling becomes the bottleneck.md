---
tags:
  - writings
  - linkedin
category:
  - "[[Posts]]"
created: 2025-08-05
published: 2025-08-09
author: "[[Jakub PruszyÅ„ski]]"
---
### Backstory
Ostatnio sporo eksperymentowaÅ‚em z iteracyjnym tworzeniem UI na webie z pomocÄ… Claude Code. Innymi sÅ‚owy dostarczamy design robiÄ…c np screenshot (moÅ¼emy rÃ³wnieÅ¼ dostarczyÄ‡ je przy pomocy  Figma MCP jeÅ›li designer dobrze zorganizowaÅ‚ przestrzeÅ„) nastÄ™pnie prosimy Claude Code aby utworzyÅ‚ komponent lub komponenty odpowiadajÄ…ce designom (zwykle takie zero-shot podejÅ›cie skutuje zaleÅ¼nie od komponentu dokÅ‚adnoÅ›ciÄ… na poziomie 75%-85% ) - dotÄ…d nie brzmi to jak Å¼adne odkrycie, ale dodajmy do tego tajny skÅ‚adnik w postaci MCP ktÃ³re pozwala robiÄ‡ screenshoty np snap-happy MCP albo playwright MCP i boom moÅ¼emy zleciÄ‡ Claude Code aby iterowaÅ‚ swojÄ… implementacje w pÄ™tli :
1. Implementacja
2. ZrÃ³b screenshot wyrenderowanego komponentu
3. OceÅ„ dokÅ‚adnoÅ›Ä‡, znajdÅº rÃ³Å¼nice, rozbieÅ¼noÅ›ci
4. WprowadÅº poprawki
I tak np 5 iteracji.
W takim podejÅ›ciu dokÅ‚adnoÅ›Ä‡ znaczÄ…co wzrasta czasem nawet pozwalajÄ…c na 100% sukces.

Po takich sukcesach postanowiÅ‚em podnieÅ›Ä‡ poprzeczkÄ™ i odwzorowaÄ‡ to podejÅ›cie ale dla aplikacji mobilnych. MiaÅ‚em 2 pomysÅ‚y : 1. WykorzystaÄ‡ te same MCP na wyciÄ…gniÄ™tym z IDE oknie preview 2. OdpalaÄ‡ preview w emulatorze. (tym sposobem i dla wÅ‚asnej eksploracji stworzyÅ‚em prosty Android Debug Bridge MCP pozwalajÄ…cy m.in sprawdzaÄ‡ deeplinki, pobieraÄ‡ listÄ™ dziaÅ‚ajÄ…cych urzÄ…dzeÅ„ etc.).

Niestety po kilku godzinach eksperymentowania i sukcesach od strony Claude Code, MCP i promptÃ³w polegaÅ‚em..na cachu. Wg moich poszukiwaÅ„ nie istnieje Å¼adne polecenie gradle ktÃ³re pozwala odÅ›wieÅ¼yÄ‡ preview. 
OdÅ›wieÅ¼anie Preview niezaleÅ¼nie czy w podglÄ…dzie czy w emulatorze nadal jest bolÄ…czkÄ…, brak hot reload dla wiÄ™kszych zmian powoduje, Å¼e mimo technologia agentowa na to pozwala to najsÅ‚abszym ogniwem okazuje siÄ™ ekosystem rozwiÄ…zaÅ„ mobilnych.
Tematu jeszcze nie porzucam, i z pewnoÅ›ciÄ… bÄ™dÄ™ dalej rozwijaÅ‚ ADB MCP, ktÃ³re przyda mi siÄ™ w innych obszarach i usprawni mÃ³j workflow. 


### Draft

**Building AI-powered iterative UI development for mobile ğŸ“±âš¡**

I've been experimenting with AI-driven UI iteration using Claude Code for web development. The workflow is surprisingly effective:

1. ğŸ“¸ Feed it a design screenshot  
2. ğŸ”§ Get 75-85% accurate component implementation  
3. ğŸ“· Use snap-happy MCP or playwright MCP to screenshot the result  
4. ğŸ”„ Let AI self-iterate through differences  
5. âœ¨ Repeat 5 times â†’ near 100% accuracy  

Web development with this approach feels almost conversational. ğŸ’¬

Naturally, I wanted to extend this to mobile development with Jetpack Compose. ğŸ“±

I built a custom Android Debug Bridge MCP to:
- ğŸ”— Check deeplinks
- ğŸ“‹ List connected devices  
- ğŸ–¼ï¸ Capture emulator screenshots
- ğŸ¯ Run composable previews

The AI agent architecture worked perfectly. The tooling integration was solid. The prompts were refined. 

But then I hit a familiar mobile development reality... ğŸ˜…

**Gradle has no cache refresh command for Compose previews.** ğŸ¤¦ğŸ»â€â™‚ï¸

Web development spoiled me with hot reload and instant previews. ğŸ”¥ Mobile development? Still waiting for that magical "gradle refresh-preview" command that doesn't exist. 

The weakest link in the chain turned out to be the development environment, not the AI workflow. ğŸ”—

**Key insight:** Even sophisticated AI workflows are constrained by the underlying tooling ecosystem. Sometimes the biggest blocker isn't your architectureâ€”it's the tools around it. ğŸ› ï¸

Still developing that ADB MCP though. Some experiments lead to useful tools even when the original goal shifts. ğŸš€

Links to snap-happy MCP, playwright MCP, and other tools mentioned are in the comments below. ğŸ‘‡

What walls have you hit when building AI tooling around existing ecosystems? Any tips for working around mobile development limitations? ğŸ¤”

### Final

AI agents meet mobile development: when tooling becomes the bottleneck ğŸ”§ğŸ“±

I've been experimenting with AI-driven UI iteration using Claude Code for web development. The workflow is surprisingly effective:

1. ğŸ“¸ Feed it a design screenshot  
2. ğŸ”§ Get 75-85% accurate component implementation  
3. ğŸ“· Use snap-happy MCP or playwright MCP to screenshot the result  
4. ğŸ”„ Let AI self-iterate through differences  
5. âœ¨ Repeat 5 times â†’ near 100% accuracy  

Web development with this approach feels almost conversational. ğŸ’¬

Naturally, I wanted to extend this to mobile development with Jetpack Compose. ğŸ“±

I built a custom Android Debug Bridge MCP to:
- ğŸ”— Check deeplinks
- ğŸ“‹ List connected devices  
- ğŸ–¼ï¸ Capture emulator screenshots
- ğŸ¯ Run composable previews

The AI agent architecture worked perfectly. The tooling integration was solid. The prompts were refined. 

But then I hit a familiar mobile development reality... ğŸ˜…

**Gradle has no cache refresh command for Compose previews.** ğŸ¤¦ğŸ»â€â™‚ï¸

Web development spoiled me with hot reload and instant previews. ğŸ”¥ Mobile development? Still waiting for that magical "gradle refresh-preview" command that doesn't exist. 

The weakest link in the chain turned out to be the development environment, not the AI workflow. ğŸ”—

**Key insight:** Even sophisticated AI workflows are constrained by the underlying tooling ecosystem. Sometimes the biggest blocker isn't your architectureâ€”it's the tools around it. ğŸ› ï¸

Still developing that ADB MCP though. Some experiments lead to useful tools even when the original goal shifts. ğŸš€

Links to snap-happy MCP, playwright MCP, and other tools mentioned are in the comments below. ğŸ‘‡

What walls have you hit when building AI tooling around existing ecosystems? Any tips for working around mobile development limitations? ğŸ¤”
